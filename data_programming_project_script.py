# -*- coding: utf-8 -*-
"""Data Programming Project Script.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1psc8JSvMxTVcQq5cgs86DYCYSt2mvPsZ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

data = pd.read_csv("shoe_trend_dataset_dirty.csv")
print(data)

import pandas as pd

data['Hashtag_Mentions'] = pd.to_numeric(data['Hashtag_Mentions'], errors='coerce')
for j in data.index:
    if pd.isna(data.loc[j, 'Hashtag_Mentions']):
        data.loc[j, 'Hashtag_Mentions'] = 60000.0

adidas_means = data[data['Brand'] == 'Adidas'][[
    'Footwear Revenue (USD)', 'Hashtag_Mentions', 'Engagement_Score', 'Sentiment_Score'
]].mean()

adidas_new_row = {
    'Brand': 'Adidas',
    'Year': 2020,
    'Footwear Revenue (USD)': adidas_means['Footwear Revenue (USD)'],
    'Hashtag_Mentions': adidas_means['Hashtag_Mentions'],
    'Engagement_Score': adidas_means['Engagement_Score'],
    'Sentiment_Score': adidas_means['Sentiment_Score']
}

data = pd.concat([data, pd.DataFrame([adidas_new_row])], ignore_index=True)


if 'Extra_Notes' in data.columns:
    data.drop(columns=['Extra_Notes'], inplace=True)

revenue_means = data.groupby('Brand')['Footwear Revenue (USD)'].mean()
engagement_means = data.groupby('Brand')['Engagement_Score'].mean()

for i in data.index:
    if pd.isna(data.loc[i, 'Footwear Revenue (USD)']):
        brand = data.loc[i, 'Brand']
        data.loc[i, 'Footwear Revenue (USD)'] = revenue_means[brand]
    if pd.isna(data.loc[i, 'Engagement_Score']):
        brand = data.loc[i, 'Brand']
        data.loc[i, 'Engagement_Score'] = engagement_means[brand]

data['Brand'] = data['Brand'].replace('nike', 'Nike')

data['Brand'] = data['Brand'].astype('category')
brand_categories = data['Brand'].cat.categories.tolist()

print(brand_categories)

print(data)

total_mentions = data.groupby('Brand')['Hashtag_Mentions'].sum().sort_values(ascending=False)

plt.figure(figsize=(10, 6))
plt.bar(total_mentions.index, total_mentions.values, color='darkorange')

plt.title('Total Hashtag Mentions by Brand')
plt.xlabel('Brand')
plt.ylabel('Total Hashtag Mentions')
plt.xticks(rotation=45)
plt.grid(axis='y', linestyle='--', alpha=0.7)

plt.show()

import matplotlib.pyplot as plt
import numpy as np

brands = ['Nike', 'Adidas', 'Puma', 'Under Armour']
points = [(0, 0), (0, 1), (1, 0), (1, 1)]

data['Year'] = pd.to_numeric(data['Year'], errors='coerce')
data['Footwear Revenue (USD)'] = pd.to_numeric(data['Footwear Revenue (USD)'], errors='coerce')
data.dropna(subset=['Year', 'Footwear Revenue (USD)'], inplace=True)

fig, axs = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle('Footwear Revenue over Years by Brand (with Trend Lines)', fontsize=16)

for brand, pos in zip(brands, points):
    subset = data[data['Brand'] == brand]
    x = subset['Year']
    y = subset['Footwear Revenue (USD)']

    axs[pos[0], pos[1]].scatter(x, y, color='darkgreen', label='Actual')

    if len(x) > 1:
        coeffs = np.polyfit(x, y, deg=1)
        trend_line = np.poly1d(coeffs)
        axs[pos[0], pos[1]].plot(x, trend_line(x), color='orange', linestyle='--', label='Trend Line')

    axs[pos[0], pos[1]].set_title(f'{brand}')
    axs[pos[0], pos[1]].set_xlabel('Year')
    axs[pos[0], pos[1]].set_ylabel('Footwear Revenue (USD)')
    axs[pos[0], pos[1]].set_xticks([2020, 2021, 2022, 2023, 2024])
    axs[pos[0], pos[1]].grid(True)
    axs[pos[0], pos[1]].legend()

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

sentiment_by_year_brand = data.groupby(['Year', 'Brand'])['Sentiment_Score'].mean().unstack()

sentiment_by_year_brand.plot(kind='bar', figsize=(12, 6), colormap='Set2')

plt.title('Average Sentiment Score')
plt.xlabel('Year')
plt.ylabel('Average Sentiment Score')
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.legend(title='Brand')
plt.tight_layout()
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score


data_copy = data.copy()

test_data = data_copy.groupby('Brand').apply(lambda x: x.sample(n=3, random_state=42)).reset_index(drop=True)

train_data = data_copy.drop(index=test_data.index)

train_encoded = pd.get_dummies(train_data, columns=['Brand'])
test_encoded = pd.get_dummies(test_data, columns=['Brand'])

for col in train_encoded.columns:
    if col not in test_encoded.columns:
        test_encoded[col] = 0
test_encoded = test_encoded[train_encoded.columns]

X_train_rev = train_encoded.drop(columns=['Footwear Revenue (USD)', 'Engagement_Score', 'Sentiment_Score'])
y_train_rev = train_encoded['Footwear Revenue (USD)']
X_test_rev = test_encoded.drop(columns=['Footwear Revenue (USD)', 'Engagement_Score', 'Sentiment_Score'])
y_test_rev = test_encoded['Footwear Revenue (USD)']


reg_revenue = LinearRegression()
reg_revenue.fit(X_train_rev, y_train_rev)
revenue_preds = reg_revenue.predict(X_test_rev)
revenue_r2 = reg_revenue.score(X_test_rev, y_test_rev)


y_train_rev_class = pd.qcut(y_train_rev, q=4, labels=False)
y_test_rev_class = pd.qcut(y_test_rev, q=4, labels=False)

rf_revenue = RandomForestClassifier()
rf_revenue.fit(X_train_rev, y_train_rev_class)
rf_revenue_preds = rf_revenue.predict(X_test_rev)
rf_revenue_accuracy = accuracy_score(y_test_rev_class, rf_revenue_preds)

log_revenue = LogisticRegression(max_iter=1000, multi_class='multinomial')
log_revenue.fit(X_train_rev, y_train_rev_class)
log_revenue_preds = log_revenue.predict(X_test_rev)
log_revenue_accuracy = accuracy_score(y_test_rev_class, log_revenue_preds)


{
    "Linear Regression R^2 for Footwear Revenue": revenue_r2,
    "Random Forest Classification Accuracy (Revenue Class)": rf_revenue_accuracy,
    "Logistic Regression Classification Accuracy (Revenue Class)": log_revenue_accuracy,
}